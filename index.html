<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=1024, user-scalable=no">

	<title>Cleaning Gritty Data to tell a story in the News Room or the Board Room</title>
	
	<!-- Required stylesheet -->
	<link rel="stylesheet" href="core/deck.core.css">
	
	<!-- Extension CSS files go here. Remove or add as needed. -->
	<link rel="stylesheet" href="extensions/goto/deck.goto.css">
	<link rel="stylesheet" href="extensions/menu/deck.menu.css">
	<link rel="stylesheet" href="extensions/navigation/deck.navigation.css">
	<link rel="stylesheet" href="extensions/status/deck.status.css">
	<link rel="stylesheet" href="extensions/hash/deck.hash.css">
	<link rel="stylesheet" href="extensions/scale/deck.scale.css">

	<!-- Style theme. More available in /themes/style/ or create your own. -->
	<link rel="stylesheet" href="themes/style/swiss.css">
	
	<!-- Transition theme. More available in /themes/transition/ or create your own. -->
	<link rel="stylesheet" href="themes/transition/horizontal-slide.css">
	
	<!-- Required Modernizr file -->
	<script src="modernizr.custom.js"></script>
</head>
<body class="deck-container">

<!-- Begin slides. Just make elements with a class of slide. -->

<section class="slide">
	<h1>Cleaning Gritty Data to tell a story in the News Room or the Board Room</h1>
</section>

<section class="slide">
	<h2>Outline</h2>
	<ol>
		<li>Cleaning data without computers (not technical)</li>
		<li>Tricks for cleaning data with computers (super technical)</li>
		<li>Telling a story (not technical)</li>
	</ol>
</section>

<section class="slide">
	<h1>Cleaning data without computers</h1>
</section>

<section class="slide">
	<h2>New Orleans Wetlands</h2>
	<p><a href="http://healthygulf.org/">The Gulf Restoration Network</a> on <a href="http://healthygulf.org/our-work/wetlands/wetlands-overview">wetlands</a></p>
	<blockquote cite="http://healthygulf.org/our-work/wetlands/wetlands-overview">
		The [Gulf Restoration Network] works to protect wetlands from reckless development,
		destructive logging practices, and harmful U.S. Army Corps of Engineers projects and policies.
	</blockquote>
	<p>More specifically</p>
	<ul>
		<li>You apply for a permit build on the wetlands in the United States.</li>
		<li>The Army Corps of Engineers can approve permits that meet certain criteria.</li>
		<li>I have no idea how the Army got this job.</li>
		<li>The Army, understandably, doesn't scrutinize permits as much as the Gulf Restoration Network would like.</li>
	</ul>
</section>

<section class="slide" style="height: 100%;">
	<h2>New Orleans Wetlands</h2>
	<p>Applications get posted to a <a href="http://www.mvn.usace.army.mil/ops/regulatory/publicnotices.asp">website</a>.</p>
	<img src="images/army404.png" alt="Screenshot of the Army Corps of Engineers website">
</section>

<section class="slide">
	<h2>New Orleans Wetlands</h2>
	<p>Applications look like this.</p>
	<img src="images/public-notice.png" alt="Excerpt of a public notice regarding a New Orleans wetland development" width="70%" >
</section>

<section class="slide">
	<h2>New Orleans Wetlands</h2>
	<p>How the Gulf Restoration Network uses these</p>
	<ol>
		<li>Read the public notices regularly.</li>
		<li>Identify applications for inappropriate things (like shopping malls).</li>
		<li>Contact 
	</ol>
	<a href="http://healthygulf.org/images/who_we_are/staff/Scott_headshot2.jpg">
		<img src="images/scott.png" style="float: left;">
	</a>
	<div>
		<p>In the past, <a href="http://healthygulf.org/images/who_we_are/staff/Scott_headshot2.jpg">Scott</a> has had to do this manually. But he doesn't really have time for that.</p>
		<p>We're using a computer program to make the first two of these steps easier.</p>
	</div>
</section>

<section class="slide">
	<h2>New Orleans Wetlands</h2>
	<p>My script extracts this information.</p>
	<img src="images/highlighted-public-notice.png" alt="Highlighted excerpt of a public notice regarding a New Orleans wetland development" width="70%" >
</section>

<section class="slide">
	<p>Pictures of sketches could go here.</p>
</section>

<section class="slide">
	<h2>New Orleans Wetlands</h2>
	<p>It also</p>
	<ul>
		<li>runs automatically every day</li>
		<li>saves all of the files</li>
		<li>checks for changes in files</li>
		<li>produces a spreadsheet of the extracted information</li>
		<li>hosts all of this on a website that Scott can access</li>
	</ul>
	<p>
		We're still working out the kinks, but the initial goal is that Scott will be able to use the spreadsheet to quickly
		find notices that he should look into further. Then he'll read the notice and take whatever actions make sense.
	</p>
</section>

<section class="slide">
	<h1>Abrupt transition</h1>
</section>

<section class="slide">
	<h1>Tricks for cleaning data with computers</h1>
</section>

<section class="slide">
	<h1>General tricks</h1>
</section>

<section class="slide">
	<h2>Learn standard XML/HTML query languages</h2>
	<p>
	Some XML/HTML parsers implement their own query languages.
	Learn standard query languages so you can switch libraries and platforms.
	</p>
	<pre><code></code></pre>
</section>

<section class="slide">
	<h2>XPath or CSS?</h2>
	<p>CSS normally makes more sense.</p>
	<ul>
		<li>CSS should run faster.</li>
		<li>More people probably know CSS.</li>
		<li>CSS is normally shorter.</li>
	</ul>
	<p>XPath is more powerful</p>
	<!-- Examples, probably on multiple slides -->
</section>

<section class="slide">
	<h2>Quickly search messy text</h2>
	<p>Removing spaces and make lowercase before searching messy text</p>
	<pre><code>
# Python
''.join(rawtext.split()).lower()

# Shell
sed -e 's/ //g' | tr '[A-Z]' '[a-z]'
</code></pre>
</section>

<section class="slide">
	<h2>Write tests</h2>
	<pre><code>
# Forty ads were randomly selected from the 389 that had been scraped by April 16.

# This sample contained eight advertisements about something other than estates.
# Originally, the scraped data were correct for all eight of these advertisements,
# and this hasn't changed with the updated scraper.
unittest.TextTestRunner(verbosity=0).run(nomatch)

# After adjusting the scraper to handle the various cleaning,
# increasing the number correct to 36 out of 40 match on all fields;
# after correcting the name suffix issue, this is now 37 of 40.
unittest.TextTestRunner(verbosity=0).run(removecomma)

# When we ignored missing fields in the original scraper,
# only 2 were incorrect. In the updated scraper,
# no incorrect data are reported.
unittest.TextTestRunner(verbosity=0).run(precision)
</code></pre>
</section>

<section class="slide">
	<h2>Initial search for structured codes is easy</h2>
	<pre><code>
# United States postal code
/([0-9]{5})-?([0-9]{4})?/

# Phone number

# ISBNs
/([0-9X-]{10,13})/
</code></pre>
	
</section>

<section class="slide">
	<h2>Use an XML/HTML parser</h2>
	<ul>
		<li></li>
		<li>C#: </li>
		<li>Java: </li>
		<li>R: </li>
		<li>php: simple_html_dom</li>
		<li>Ruby: Nokogiri</li>
		<li>Python: lxml, BeautifulSoup</li>
	</ul>
</section>

<section class="slide">
	<h2>split-apply-combine</h2>
	You've probably heard this already. If not, read Hadley's paper or watch his talks.
</section>

<section class="slide">
	<h2>Document-like interfaces for loading data to relational databases</h2>
	<p>Document databases have nice interfaces. We can mimic this with relational databases.</p>
	<pre><code>
dt = DumpTruck()
dt.insert({"payload": "10 tons"})
</code></pre>
	<p>Similar libraries</p>
	<ul>
		<li><a href="http://www.dumptruck.io">dumptruck</a> (Python)</li>
		<li>node-sqlite (node)</li>
		(ruby)
	</ul>
</section>

<section class="slide">
	<h2>Updating factor levels</h2>
	<p>In languages with dictionaries</p>
	<pre><code>
</pre></code>
	<p>In R</p>
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h2>Validating addresses</h2>
Zipcode lookup API https://views.scraperwiki.com/run/usps_lookup/
</section>

<section class="slide">
	<h2>Skip annoying sections</h2>
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h1>Python tricks</h1>
</section>

Skipping unusually complex sections of files and maybe doing them manually (like odyssey and dairy)
<section class="slide">
	<h2>unidecode</h2>
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h2>lxml.etree._HtmlElement.make_links_absolute</h2>
	http://lxml.de/lxmlhtml.html
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h2>requests</h2>
	copying a request from the browser network analyzer thingy into a requests request
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h1>Shell tricks</h1>
</section>

<section class="slide">
	<h2></h2>
tr, sed 1d, wc
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h2></h2>
pdftohtml, pdftotext, pdfimages, inkscape
	<pre><code>
</pre></code>
</section>

<section class="slide">
	<h1>Telling a story</h1>
	<!-- You don't need to know anything as fancy as what I just told you. -->
</section>

<section class="slide">
	<h2></h2>
So you can go through this process to clean up all the data, but when you're
just presenting some figures, you can do some stupidly easy analysis instead.

Talk about stupidly basic analyses and how that's already useful.
* FALLOS
* String matches (SELECT count(*) from foo where bar LIKE %baz%;)
* 
</section>

<section class="slide">
	<h1><span style="font-size: 4em;">!</span></h1>
	<!-- End -->
</section>

<!-- End slides. -->


<!-- Begin extension snippets. Add or remove as needed. -->

<!-- deck.navigation snippet -->
<a href="#" class="deck-prev-link" title="Previous">&#8592;</a>
<a href="#" class="deck-next-link" title="Next">&#8594;</a>

<!-- deck.status snippet -->
<p class="deck-status">
	<span class="deck-status-current"></span>
	/
	<span class="deck-status-total"></span>
</p>

<!-- deck.goto snippet -->
<form action="." method="get" class="goto-form">
	<label for="goto-slide">Go to slide:</label>
	<input type="text" name="slidenum" id="goto-slide" list="goto-datalist">
	<datalist id="goto-datalist"></datalist>
	<input type="submit" value="Go">
</form>

<!-- deck.hash snippet -->
<a href="." title="Permalink to this slide" class="deck-permalink">#</a>

<!-- End extension snippets. -->


<!-- Required JS files. -->
<script src="jquery-1.7.2.min.js"></script>
<script src="core/deck.core.js"></script>

<!-- Extension JS files. Add or remove as needed. -->
<script src="core/deck.core.js"></script>
<script src="extensions/hash/deck.hash.js"></script>
<script src="extensions/menu/deck.menu.js"></script>
<script src="extensions/goto/deck.goto.js"></script>
<script src="extensions/status/deck.status.js"></script>
<script src="extensions/navigation/deck.navigation.js"></script>
<script src="extensions/scale/deck.scale.js"></script>

<!-- Piwik --> 
<script type="text/javascript">
var pkBaseURL = (("https:" == document.location.protocol) ? "https://piwik.thomaslevine.com/" : "http://piwik.thomaslevine.com/");
document.write(unescape("%3Cscript src='" + pkBaseURL + "piwik.js' type='text/javascript'%3E%3C/script%3E"));
</script><script type="text/javascript">
try {
var piwikTracker = Piwik.getTracker(pkBaseURL + "piwik.php", 10);
piwikTracker.trackPageView();
piwikTracker.enableLinkTracking();
} catch( err ) {}
</script><noscript><p><img src="http://piwik.thomaslevine.com/piwik.php?idsite=10" style="border:0" alt="" /></p></noscript>
<!-- End Piwik Tracking Code -->

<!-- Initialize the deck. You can put this in an external file if desired. -->
<script>
	$(function() {
		$.deck('.slide');
	});
</script>
</body>
</html>
